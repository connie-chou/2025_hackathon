{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to use text prompts to find cigarette / wine bottle / beer can... Great for hackathon demo and bootstrapping labels when I don’t have data yet\n",
    "# But find out it's not very accurate => abandon this approach\n",
    "\n",
    "%pip install --upgrade pip\n",
    "\n",
    "# PyTorch (CUDA 12.1 wheels). If your CUDA is different, see note below.\n",
    "#%pip install --index-url https://download.pytorch.org/whl/cu121 torch torchvision torchaudio\n",
    "\n",
    "# Ultralytics YOLO + essentials\n",
    "%pip install ultralytics opencv-python tqdm matplotlib numpy pyyaml pandas\n",
    "\n",
    "# Transformers for the OWL-ViT open-vocabulary demo\n",
    "%pip install transformers accelerate timm pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, subprocess, sys\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA device:\", torch.cuda.get_device_name(0))\n",
    "print(\"\\n=== nvidia-smi ===\")\n",
    "try:\n",
    "    print(subprocess.check_output([\"nvidia-smi\"]).decode())\n",
    "except Exception as e:\n",
    "    print(\"nvidia-smi not available:\", e, file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import torch\n",
    "from transformers import OwlViTProcessor, OwlViTForObjectDetection\n",
    "from pathlib import Path\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_id = \"google/owlvit-base-patch32\"\n",
    "processor = OwlViTProcessor.from_pretrained(model_id)\n",
    "model = OwlViTForObjectDetection.from_pretrained(model_id).to(device)\n",
    "\n",
    "# ⬇️ replace with your test image\n",
    "test_image_path = str(Path(\"~/images/alochol2.jpeg\").expanduser())\n",
    "\n",
    "image = Image.open(test_image_path).convert(\"RGB\")\n",
    "texts = [[\"car plate\",\"number plate\",\"license plate\",\"cigarette\",\"smoking\",\"alcohol\",\"wine bottle\",\"beer can\"]]\n",
    "\n",
    "inputs = processor(text=texts, images=image, return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "target_sizes = torch.tensor([image.size[::-1]]).to(device)  # (h, w)\n",
    "results = processor.post_process_object_detection(outputs=outputs, target_sizes=target_sizes)[0]\n",
    "\n",
    "draw = image.copy()\n",
    "draw_ctx = ImageDraw.Draw(draw)\n",
    "W, H = image.size\n",
    "\n",
    "detections = []\n",
    "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "    score = float(score.item())\n",
    "    if score < 0.20:\n",
    "        continue\n",
    "    ymin, xmin, ymax, xmax = [float(x) for x in box.tolist()]\n",
    "    detections.append({\n",
    "        \"label\": texts[0][int(label)],\n",
    "        \"score\": score,\n",
    "        \"xyxy\": [xmin, ymin, xmax, ymax]\n",
    "    })\n",
    "    draw_ctx.rectangle([(xmin, ymin), (xmax, ymax)], outline=\"red\", width=3)\n",
    "    draw_ctx.text((xmin, max(0, ymin-10)), f\"{texts[0][int(label)]} {score:.2f}\", fill=\"red\")\n",
    "\n",
    "display(draw)\n",
    "print(\"Detections:\", detections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
